{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3ec7717-c23a-4c04-b0f5-e036ed2e1742",
   "metadata": {},
   "source": [
    "<img src=\"https://stijl.kuleuven.be/releases/latest/img/svg/logo.svg\" alt=\"KU Leuven\">\n",
    "\n",
    "# **Exploring *CroALa* and Marko Marulić**\n",
    "\n",
    "An exam project for Scripting Languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbad04d-d082-4223-9755-0b3e728c2579",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "<b> THIS NOTEBOOK IS A WORK IN PROGRESS </b>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadd23c1-41c1-45a6-8b7c-f75b65aa327c",
   "metadata": {},
   "source": [
    "This is a Juypter notebook for the exam project for the [Scripting Languages \\[G0W95B\\]](https://onderwijsaanbod.kuleuven.be/2025/syllabi/e/G0W95BE.html) course of the [Digital Humanities](https://www.kuleuven.be/programmes/master-digital-humanities) programme at [KU Leuven](https://www.kuleuven.be/english/kuleuven/). \n",
    "\n",
    "Author:\n",
    "<br> Petar Soldo\n",
    "<br> r1076709\n",
    "<br> [petar.soldo@student.kuleuven.be](mailto:petar.soldo@student.kuleuven.be)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98302d6f-4835-48e9-89d7-40917c5a775b",
   "metadata": {},
   "source": [
    "## About the project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c940c80-b724-4b6a-89bb-16ed5da5dc9a",
   "metadata": {},
   "source": [
    "The main goal of the project is to perform an \"exploratory analysis of data\" and \"to (...) independently apply the programming techniques explored during the course\".\n",
    "\n",
    "For this purpose, *CroALa* was chosen as a dataset to be analyzed. \n",
    "\n",
    "The project has two main goals.\n",
    "\n",
    "1. Perform a short analysis of the documents in _CroALa_ based on their metadata.\n",
    "2. Perform a short text analysis of selected works by Marko Marulić."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3274b4-08a1-4835-a6a4-180f0d4d56e4",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/d/da/Marko_Marulic_bust_-_lighting_fix.jpg/250px-Marko_Marulic_bust_-_lighting_fix.jpg\" alt=\"Marko Marulić\">\n",
    "\n",
    "*Bust of Marko Marulić of Split, Croatian poet, by Ivan Meštrović*\n",
    "\n",
    "*DIREKTOR (talk · contribs), CC0, via Wikimedia Commons*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799646d6-f1fc-403d-8d9d-5713ba66147b",
   "metadata": {},
   "source": [
    "## *CroALa*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e74857b-b515-41ac-b7a4-c8766cfe860a",
   "metadata": {},
   "source": [
    "### About *CroALa*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787a7497-8f91-471b-8b19-dd61f1385a28",
   "metadata": {},
   "source": [
    "TBA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f38615-bf3b-4152-a676-6ab6507c19a2",
   "metadata": {},
   "source": [
    "### What do I want to do?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4780bba6-8b97-44ce-bc56-23d15babe242",
   "metadata": {},
   "source": [
    "I want to build a table with the metadata from the XML files in the repository.\n",
    "\n",
    "To do this I will make a small piece of code that (i) opens every file and extracts the data we need to a list, (ii) appends the list to a dictionary, (iii) turns the dictionary to a *Pandas* dataframe and (iv) exports the dataframe to CSV file. \n",
    "\n",
    "The data I want in my table is:\n",
    "- name of the file\n",
    "- title of the work\n",
    "- name of the first author\n",
    "- date related to the first author\n",
    "- all mentioned authors and appurtenant dates\n",
    "- editors of the edition\n",
    "- languages attributed to the document\n",
    "- date(s) of creation\n",
    "- place(s) of creation\n",
    "- typus\n",
    "- genres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421508f3-705c-4fa1-b6c7-c4be7abacfae",
   "metadata": {},
   "source": [
    "### Retrieving metadata about the documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4846b4eb-c792-4664-8265-4b15c91a91b7",
   "metadata": {},
   "source": [
    "**NOTE**: This part of the project was largely based on the blog post [*Parsing TEI XML documents with Python*](https://komax.github.io/blog/text/python/xml/parsing_tei_xml_python/) by Maximilian Konzack (2019)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c607f7-7535-4b85-8887-a9f239e4cea9",
   "metadata": {},
   "source": [
    "First, let's import all the libraries we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afe8d655-81ed-47ab-bffd-83ee1475e504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "#Make sure you have SoupSieve installed (usually it installs together with BeautifulSoup, when using pip to install)\n",
    "import lxml\n",
    "from glob import glob\n",
    "from os.path import basename\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc28aa9b-d726-4ef8-b4ac-2276df0aa36a",
   "metadata": {},
   "source": [
    "We define two functions:\n",
    "1. *read_tei* for reading the files and\n",
    "2. *e2t*, short for *element to text*, for extracting the text from an XML element.\n",
    "\n",
    "Both of these functions were slightly adapted from the aforementioned project: https://komax.github.io/blog/text/python/xml/parsing_tei_xml_python/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2a10e24-d126-4397-ba5d-0c06142a1e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take an XML file and return it as a BeutifulSoup object\n",
    "def read_tei(tei_file):\n",
    "    with open(tei_file, 'r', encoding = 'utf-8') as tei:\n",
    "        soup = BeautifulSoup(tei, 'xml')\n",
    "        return soup\n",
    "# We can use this new object to navigate the XML document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74492710-4b9e-4d3d-be65-f76bfb38ee2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take an XML element and return just its contents\n",
    "def e2t(elem, default=''):\n",
    "    if elem:\n",
    "        return re.sub(r'\\s+', ' ', elem.getText(strip=True)) \n",
    "        # The regular expression is used to avoid often occuring multiple whitespaces\n",
    "        # and unsual line breaks, not removed by (strip=True)\n",
    "    else:\n",
    "        return default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bd7977-2b7d-4930-81be-d8b2844e5ada",
   "metadata": {},
   "source": [
    "### Extracting the elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a65c99-fc9c-4a6b-93c8-7e347c018cb5",
   "metadata": {},
   "source": [
    "We can shortly demonstrate how this works. We will choose the first document from the *\"texts\"* directory.\n",
    "\n",
    "Let's extract some simple metadata from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a9e1dbc-35c0-44ed-a2e2-ccc82ffda198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carmina occasionalia e codice Traguriensi Variorum Dalmaticorum, versio electronica\n",
      "Auctores varii\n",
      "1565-1650\n"
     ]
    }
   ],
   "source": [
    "#This loads the document:\n",
    "document = read_tei(\"txts/aa-vv-carm-occ-vd.xml\")\n",
    "\n",
    "#This finds the title:\n",
    "print(e2t(document.find(\"title\")))\n",
    "\n",
    "#This finds the (first) author:\n",
    "print(e2t(document.find(\"author\")))\n",
    "\n",
    "#This finds the creation date:\n",
    "print(e2t(document.select_one(\"profileDesc creation date\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f45a36-48ef-4fdf-81d6-37f5116bc3c0",
   "metadata": {},
   "source": [
    "Sometimes, there is more than one piece of information we want to extract from an XML element. It seems that *BeutifulSoup* always returns a list in this case. It is important to not that the `getText()` method does not work on a list, so, if we wish to extract the text from multiple elements, we must iterate throught them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0153ad97-a903-4792-80e3-ee88ef76baff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auctores varii\n",
      "Grauisius, Iacobus\n",
      "Mladinić, Sebastijan1561/1563 - 1620-21\n",
      "Mazarelli, Valerio\n",
      "Statilić, Marinc. 1650\n",
      "Pridojević, Ivanc. 1600\n",
      "Vranius\n",
      "Gaudentius\n",
      "Matthaeus Desseus Ragusinus\n",
      "Michael Racetinus\n"
     ]
    }
   ],
   "source": [
    "for author in document.select(\"titleStmt author\"):\n",
    "    print (e2t(author))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b42077-d6cd-4652-a234-502745cc31ab",
   "metadata": {},
   "source": [
    "At first I thought of using the `find` and `find_all` methods, but it seems that `select` and `select_one` allow defining a path by simply writing the elements, separated by a whitespace. This would require chaining the methods when using `find/find_all`.\n",
    "\n",
    "Thus the selection of all the `author` elements above, using `find_all` would look like this: `document.find(\"titleStmt\").find_all(\"author\")`. The `select(_one)` methods also have a nicer way to access an attribute value.\n",
    "\n",
    "I thus find the CSS selector methods (`select/select_one`) much more elegant and sufficiently useful for this part of the project.\n",
    "\n",
    "More about this issue:\n",
    "- https://www.crummy.com/software/BeautifulSoup/bs4/doc/#css-selectors-through-the-css-property\n",
    "- https://stackoverflow.com/a/38033910"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20547587-13f9-4061-82c0-d755316439a6",
   "metadata": {},
   "source": [
    "### Checking how elements behave"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc3eaf8-be3d-4096-90a0-5f0bbabab1bb",
   "metadata": {},
   "source": [
    "Before we go on to extracting the metadata, we should first check what do some of our elements look like. I was forced to perform this check *after* I started buidling a table, because I realized I was not extracting information I wanted or thought I was. However, I will, providently, explain what I checked for and how I did it before going on :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9b9683-1a62-4b54-858d-53d8027bdda8",
   "metadata": {},
   "source": [
    "The elements which needed inspecting were `author` and `creation`. They sometimes encode information in different ways, i.e. by using different tags."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca5a4db-aadd-416c-8ba7-19bd90d748a1",
   "metadata": {},
   "source": [
    "We will first inspect the `author` tag. We make use of the `name` method to find the names of the child elements of the `author` element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4f03362-9566-4389-807e-17704809c181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{None, '', 'persName', 'date', 'ref', 'placeName', 'orgName'}\n"
     ]
    }
   ],
   "source": [
    "tagnames = []\n",
    "# Iterate through documents and save all tag names to the tagnames list.\n",
    "for filename in glob(\"txts/*.xml\"):\n",
    "    doc = read_tei(filename)\n",
    "    if doc.select_one(\"titleStmt author\"):\n",
    "        for element in doc.select_one(\"titleStmt author\"):\n",
    "            tagnames.append(element.name)\n",
    "    else:\n",
    "        tagnames.append('')\n",
    "# Make a set to leave only unique values\n",
    "tagset = set(tagnames)\n",
    "print(tagset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e586ed-4157-48cd-a4d4-3cb3e7693483",
   "metadata": {},
   "source": [
    "We now have a list (a set to be more precise) of all tags which appear as chidren of the `author` tag. We go on further to inspect in which files do these tags appear and what do they contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce584a22-5fac-45f9-8830-65259ca0c8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to store the elements we want to inspect\n",
    "ref= []\n",
    "placeName = []\n",
    "orgName = []\n",
    "for file in glob(\"txts/*.xml\"):\n",
    "    doc = read_tei(file)\n",
    "    # Find the elemenets and store the to list, together with the filename\n",
    "    if doc.select_one(\"titleStmt author ref\"):\n",
    "        ref.append([file, doc.select_one(\"titleStmt author ref\")])\n",
    "    if doc.select_one(\"titleStmt author placeName\"):\n",
    "        placeName.append([file, doc.select_one(\"titleStmt author placeName\")])\n",
    "    if doc.select_one(\"titleStmt author orgName\"):\n",
    "        orgName.append([file, doc.select_one(\"titleStmt author orgName\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cae90bc-cd7b-405e-ac6c-986730a5aef8",
   "metadata": {},
   "source": [
    "We can now see what type of data these tags marks contain and in which file we can find them. This can further on be used to indeed inspect the files and decide how to extract the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1be27e62-2117-4b46-a526-d3e8ec0c6ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['txts\\\\andreis-f-1529-02-15.xml',\n",
      "  <ref target=\"http://www.wikidata.org/entity/Q16115490\" type=\"wikidata\">Andreis, Franjo Trankvil</ref>],\n",
      " ['txts\\\\cikulin-if-ideae.xml',\n",
      "  <ref target=\"http://www.wikidata.org/entity/Q860595\">Čikulin, Ivan Franjo</ref>],\n",
      " ['txts\\\\donat-mandel-sissiensis.xml',\n",
      "  <ref target=\"donat01\">Donati, Ivan</ref>]]\n",
      "[['txts\\\\barletius-scodrensi-obsidione-1504.xml',\n",
      "  <placeName>Skadar</placeName>],\n",
      " ['txts\\\\barletius-vita-castrioti-1508.xml', <placeName>Skadar</placeName>],\n",
      " ['txts\\\\goineo-gb-situistriae-1543.xml', <placeName>Piran</placeName>]]\n",
      "[['txts\\\\aa-vv-carm-occ-vd.xml',\n",
      "  <orgName ref=\"#varii-1650\">Auctores varii</orgName>],\n",
      " ['txts\\\\aa-vv-epigr-mulla.xml',\n",
      "  <orgName ref=\"#varii-1552\">Auctores varii</orgName>],\n",
      " ['txts\\\\aa-vv-epigr-tres.xml',\n",
      "  <orgName ref=\"#varii-1600\">Auctores varii</orgName>]]\n"
     ]
    }
   ],
   "source": [
    "pprint(ref[:3])\n",
    "pprint(placeName[:3])\n",
    "pprint(orgName[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f55653c-3f1a-4b2d-b4cc-992d03496464",
   "metadata": {},
   "source": [
    "We repeat the process with the `creation` element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daaab013-530e-47fc-9379-143962ab68a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagnames_2 = []\n",
    "\n",
    "for filename in glob(\"txts/*.xml\"):\n",
    "    doc = read_tei(filename)\n",
    "    if doc.select_one(\"profileDesc creation\"):\n",
    "        for element in doc.select_one(\"profileDesc creation\"):\n",
    "            tagnames_2.append(element.name)\n",
    "    else:\n",
    "        tagnames_2.append('')\n",
    "tagset_2 = set(tagnames_2)\n",
    "\n",
    "address_c = []\n",
    "placeName_c = []\n",
    "\n",
    "for file in glob(\"txts/*.xml\"):\n",
    "    doc = read_tei(file)\n",
    "    if doc.select_one(\"profileDesc creation address\"):\n",
    "        address_c.append([file, doc.select_one(\"profileDesc creation address\")])\n",
    "    if doc.select_one(\"profileDesc creation placeName\"):\n",
    "        placeName_c.append([file, doc.select_one(\"profileDesc creation placeName\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed166582-417c-4575-8469-14d78043210f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{None, 'date', 'placeName', 'address'}\n",
      "[['txts\\\\aa-vv-carmina-vgc.xml',\n",
      "  <address>\n",
      "<addrLine>Romae</addrLine>\n",
      "<addrLine>Ragusae</addrLine>\n",
      "</address>],\n",
      " ['txts\\\\andreis-f-philos.xml',\n",
      "  <address>\n",
      "<addrLine>Cracoviae</addrLine>\n",
      "<addrLine>Posnaniae</addrLine>\n",
      "</address>],\n",
      " ['txts\\\\baricev-aa-epist-penzel.xml',\n",
      "  <address>\n",
      "<addrLine>Zagrabiae</addrLine>\n",
      "</address>]]\n",
      "[['txts\\\\aa-vv-supetarski.xml', <placeName>Split</placeName>],\n",
      " ['txts\\\\adam-parisius-vaticanum-officium-1059.xml',\n",
      "  <placeName ref=\"http://www.wikidata.org/entity/Q1663\">Split</placeName>],\n",
      " ['txts\\\\adam-radauanus-traditio.xml',\n",
      "  <placeName ref=\"http://www.wikidata.org/entity/Q396372\">Nin</placeName>]]\n"
     ]
    }
   ],
   "source": [
    "pprint(tagset_2)\n",
    "pprint(address_c[:3])\n",
    "pprint(placeName_c[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa012547-f8c9-4763-8ee1-cc0bf9f0ecac",
   "metadata": {},
   "source": [
    "This could all be done in quarter of the time by simply placing all the queries under one \"read file\" loop, but it was separated here to give a better idea of what our code did. I will probably join them in later version of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a47810-63cd-4057-9ede-33700ed85cd2",
   "metadata": {},
   "source": [
    "### Making a table out of the metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03163387-ec52-41a2-8b49-39f7ed7bd151",
   "metadata": {},
   "source": [
    "We can finally make a table out of the metadata. We initialize a list `croala_data` to which we will append a dictionary of values corresponding to the metadata for every XML file in our `txts` directory. This list of dictionaries is  then used to create a Panadas dataframe. In the end, we dump it to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05968018-5d95-4432-a7cd-1487effb3733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>titles</th>\n",
       "      <th>first_author</th>\n",
       "      <th>first_author_date</th>\n",
       "      <th>all_authors</th>\n",
       "      <th>editors</th>\n",
       "      <th>language</th>\n",
       "      <th>date</th>\n",
       "      <th>place</th>\n",
       "      <th>typus</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa-vv-carm-occ-vd.xml</td>\n",
       "      <td>Carmina occasionalia e codice Traguriensi Vari...</td>\n",
       "      <td>Auctores varii</td>\n",
       "      <td></td>\n",
       "      <td>[Auctores varii, Grauisius, Iacobus, Mladinić,...</td>\n",
       "      <td>[Neven Jovanović]</td>\n",
       "      <td>[lat]</td>\n",
       "      <td>[1565-1650]</td>\n",
       "      <td></td>\n",
       "      <td>poesis</td>\n",
       "      <td>[poesis - epigramma, poesis - elegia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa-vv-carmina-vgc.xml</td>\n",
       "      <td>Carmina minora ex libro De vita et gestis Chri...</td>\n",
       "      <td>Bunić, Jakov</td>\n",
       "      <td>1469-1534</td>\n",
       "      <td>[Bunić, Jakov, 1469-1534, Caluus, Hieronymus, ...</td>\n",
       "      <td>[Neven Jovanović]</td>\n",
       "      <td>[lat]</td>\n",
       "      <td>[a. 1502--1526]</td>\n",
       "      <td>[Romae, Ragusae]</td>\n",
       "      <td>poesis</td>\n",
       "      <td>[poesis - carmen, poesis - epigramma, poesis -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aa-vv-epigr-mulla.xml</td>\n",
       "      <td>Ad clarissimum uirum dominum Benedictum de Mul...</td>\n",
       "      <td>Auctores varii</td>\n",
       "      <td></td>\n",
       "      <td>[Auctores varii, Martinčić, Jerolim, Alberti, ...</td>\n",
       "      <td>[Neven Jovanović]</td>\n",
       "      <td>[lat]</td>\n",
       "      <td>[1549-1552]</td>\n",
       "      <td></td>\n",
       "      <td>poesis</td>\n",
       "      <td>[poesis - epigramma, poesis - encomium]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aa-vv-epigr-natal.xml</td>\n",
       "      <td>Epigrammata in codice Natalis, versio electronica</td>\n",
       "      <td>Kabalin, Grgur</td>\n",
       "      <td></td>\n",
       "      <td>[Kabalin, Grgur, Tolimerić, Ilija, m. 1537?]</td>\n",
       "      <td>[Miroslav Marcovich]</td>\n",
       "      <td>[lat]</td>\n",
       "      <td>[post 1536]</td>\n",
       "      <td></td>\n",
       "      <td>poesis</td>\n",
       "      <td>[poesis - carmen, poesis - elegia, poesis - ep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aa-vv-epigr-tres.xml</td>\n",
       "      <td>Tres invicem epigrammata, versio electronica</td>\n",
       "      <td>Auctores varii</td>\n",
       "      <td></td>\n",
       "      <td>[Auctores varii, Kabalin, Grgur, Chrysogonus]</td>\n",
       "      <td>[Neven Jovanović]</td>\n",
       "      <td>[lat]</td>\n",
       "      <td>[c. 1600.]</td>\n",
       "      <td></td>\n",
       "      <td>poesis</td>\n",
       "      <td>[poesis - epigramma]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                filename                                             titles  \\\n",
       "0  aa-vv-carm-occ-vd.xml  Carmina occasionalia e codice Traguriensi Vari...   \n",
       "1  aa-vv-carmina-vgc.xml  Carmina minora ex libro De vita et gestis Chri...   \n",
       "2  aa-vv-epigr-mulla.xml  Ad clarissimum uirum dominum Benedictum de Mul...   \n",
       "3  aa-vv-epigr-natal.xml  Epigrammata in codice Natalis, versio electronica   \n",
       "4   aa-vv-epigr-tres.xml       Tres invicem epigrammata, versio electronica   \n",
       "\n",
       "     first_author first_author_date  \\\n",
       "0  Auctores varii                     \n",
       "1    Bunić, Jakov         1469-1534   \n",
       "2  Auctores varii                     \n",
       "3  Kabalin, Grgur                     \n",
       "4  Auctores varii                     \n",
       "\n",
       "                                         all_authors               editors  \\\n",
       "0  [Auctores varii, Grauisius, Iacobus, Mladinić,...     [Neven Jovanović]   \n",
       "1  [Bunić, Jakov, 1469-1534, Caluus, Hieronymus, ...     [Neven Jovanović]   \n",
       "2  [Auctores varii, Martinčić, Jerolim, Alberti, ...     [Neven Jovanović]   \n",
       "3       [Kabalin, Grgur, Tolimerić, Ilija, m. 1537?]  [Miroslav Marcovich]   \n",
       "4      [Auctores varii, Kabalin, Grgur, Chrysogonus]     [Neven Jovanović]   \n",
       "\n",
       "  language             date             place   typus  \\\n",
       "0    [lat]      [1565-1650]                    poesis   \n",
       "1    [lat]  [a. 1502--1526]  [Romae, Ragusae]  poesis   \n",
       "2    [lat]      [1549-1552]                    poesis   \n",
       "3    [lat]      [post 1536]                    poesis   \n",
       "4    [lat]       [c. 1600.]                    poesis   \n",
       "\n",
       "                                              genres  \n",
       "0              [poesis - epigramma, poesis - elegia]  \n",
       "1  [poesis - carmen, poesis - epigramma, poesis -...  \n",
       "2            [poesis - epigramma, poesis - encomium]  \n",
       "3  [poesis - carmen, poesis - elegia, poesis - ep...  \n",
       "4                               [poesis - epigramma]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "croala_data = []\n",
    "\n",
    "for filename in glob(\"txts/*.xml\"):\n",
    "    doc = read_tei(filename)\n",
    "    \n",
    "    # Extract titles\n",
    "    titles = e2t(doc.select_one(\"titleStmt title\"))\n",
    "\n",
    "    # Extract first author name\n",
    "    if doc.select_one(\"titleStmt author\"):\n",
    "        if doc.select_one(\"titleStmt author\").find(\"orgName\"):\n",
    "            first_author = e2t(doc.select_one(\"titleStmt author orgName\"))\n",
    "        elif doc.select_one(\"titleStmt author\").find(\"persName\"):\n",
    "            first_author = e2t(doc.select_one(\"titleStmt author persName\"))\n",
    "    else:\n",
    "        first_author = ''\n",
    "\n",
    "    #Extrat first author date\n",
    "    if doc.select_one(\"titleStmt author\"):\n",
    "        first_author_date = e2t(doc.select_one(\"titleStmt author\").find(\"date\"))\n",
    "    else:\n",
    "        first_author_date = ''\n",
    "    \n",
    "    # Extract all authors\n",
    "    all_authors = [(re.sub(r'\\s+', ' ', a.get_text(separator = \", \", strip=True))) for a in doc.select(\"author\")]\n",
    "\n",
    "    # Extract editors\n",
    "    editors = [e2t(e) for e in doc.select(\"titleStmt editor persName ref\")]\n",
    "\n",
    "    # Extract language\n",
    "    language = [l[\"ident\"] for l in doc.select(\"profileDesc langUsage language\")]\n",
    "\n",
    "    # Extract place\n",
    "    if doc.select_one(\"profileDesc creation\"):\n",
    "        if doc.select(\"profileDesc creation placeName\"):\n",
    "            place = [e2t(pl) for pl in doc.select(\"profileDesc creation placeName\")]\n",
    "        elif doc.select_one(\"profileDesc creation address\"):\n",
    "            place = [e2t(add) for add in doc.select(\"profileDesc creation addrLine\")]\n",
    "        else:\n",
    "            place = ''\n",
    "    else:\n",
    "        place = ''\n",
    "\n",
    "    # Extract date\n",
    "    date = [e2t(d) for d in doc.select(\"profileDesc creation date\")]\n",
    "\n",
    "    # Extract typus\n",
    "    typus = e2t(doc.select_one(\"textClass keywords[scheme=typus] term\"))\n",
    "\n",
    "    # Extract genres\n",
    "    genres = [e2t(g) for g in doc.select(\"textClass keywords[scheme=genre] term\")]\n",
    "\n",
    "    # Append as a dictionary\n",
    "    croala_data.append({\n",
    "        \"filename\": basename(filename),\n",
    "        \"titles\": titles,\n",
    "        \"first_author\": first_author,\n",
    "        \"first_author_date\": first_author_date,\n",
    "        \"all_authors\": all_authors,\n",
    "        \"editors\": editors,\n",
    "        \"language\": language,\n",
    "        \"date\": date,\n",
    "        \"place\": place,\n",
    "        \"typus\": typus,\n",
    "        \"genres\": genres\n",
    "    })\n",
    "\n",
    "# Convert to a dataframe\n",
    "croala_df = pd.DataFrame(croala_data)\n",
    "croala_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29868982-5b08-44c2-aa07-1fef1d84ce21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export to a csv file\n",
    "croala_df.to_csv(\"croala_metadata.csv\", index = False, encoding = 'utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
